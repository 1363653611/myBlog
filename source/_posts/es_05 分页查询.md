---
title: ElasticSearch 分页查询的4种解决方案
date: 2021-02-12 13:33:36
tags:
  - elasticsearch    
categories:
  - elasticsearch
#top: 1
topdeclare: false
reward: true
---

# ElasticSearch 分页查询的4种解决方案

# from + size 浅分页

语法： 使用 from + size 方式

```shell
GET /my_index/_doc/search
{
	"query": { "match_all": {}},
    "from": 10,
    "size": 5
}
```

<!--more-->

从搜索结果中取第10条开始的5条数据.

##  查询语句在 Elasticsearch 集群内部是怎么执行？

假设该索引只有primary shards，没有 replica shards，假设10个分片。搜索一般包括两个阶段，query 和 fetch 阶段，query 阶段确定要取哪些doc，fetch 阶段取出具体的 doc。

### query 阶段

1.  Client 发送一次搜索请求，node1 接收到请求，然后，node1 创建一个大小为 from + size 的优先级队列用来存结果，我们管 node1 叫 coordinating node。
2. coordinating node将请求广播到涉及到的 shards，每个 shard 在内部执行搜索请求，然后，将结果存到内部的大小同样为 from + size 的优先级队列里，可以把优先级队列理解为一个包含 top N 结果的列表。
3. 每个 shard 把暂存在自身优先级队列里的数据返回给 coordinating node，coordinating node 拿到各个 shards 返回的结果后对结果进行一次合并，产生一个全局的优先级队列，存到自身的优先级队列里。

在上面的过程中，coordinating node 拿到 (from + size) * 分片数目 条数据，然后合并并排序后选择前面的 from + size 条数据存到优先级队列，以便 fetch 阶段使用。

各个分片返回给 coordinating node 的数据用于选出前 from + size 条数据，所以，只需要返回唯一标记 doc 的 _id 以及用于排序的 _score 即可，这样也可以保证返回的数据量足够小。

coordinating node 计算好自己的优先级队列后，query 阶段结束，进入 fetch 阶段。

###  fetch 阶段

query 阶段知道了要取哪些数据，但是并没有取具体的数据，这就是 fetch 阶段要做的。

1. coordinating node 发送 GET 请求到相关shards。
2. shard 根据 doc 的 _id 取到数据详情，然后返回给 coordinating node。
3. coordinating node 返回数据给 Client。

coordinating node 的优先级队列里有 from + size 个 _doc _id，但是，在 fetch 阶段，并不需要取回所有数据，在上面的例子中，前10条数据是不需要取的，只需要取优先级队列里的第11到15条数据即可。

需要取的数据可能在不同分片，也可能在同一分片，coordinating node 使用 multi-get 来避免多次去同一分片取数据，从而提高性能。

# scroll 深分页

**from+size查询方式在10000-50000条数据（1000到5000页）以内的时候还是可以的，但是如果数据过多的话，就会出现深分页问题。**

eg：

一个索引，有10亿数据，分10个 shards，然后，一个搜索请求，from=1,000,000，size=100，这时候，会带来严重的性能问题，CPU，内存，IO，网络带宽。

## scroll 

scroll 类似于sql中的cursor，使用scroll，每次只能获取一页的内容，然后会返回一个scroll_id。根据返回的这个scroll_id可以不断地获取下一页的内容。

**瓶颈：** scroll并不适用于有跳页的情景。

#### 操作

- **初始搜索**： 请求应该在查询中指定 scroll 参数，如 ?scroll=1m,这可以告诉 Elasticsearch 需要保持搜索的上下文环境多久。

```shell
GET /twitter/_search?scroll=1m
{
  "query": {
    "match_all": {}
  },
  "size": 1,
  "from": 0
}
# 返回结果
{
  "_scroll_id" : "DnF1ZXJ5VGhlbkZldGNoAwAAAAAAF2taFjZudThqQXAyVGVxWk04MUM3eEZDVEEAAAAAABdrWxY2bnU4akFwMlRlcVpNODFDN3hGQ1RBAAAAAAAXa1kWNm51OGpBcDJUZXFaTTgxQzd4RkNUQQ==",
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 3,
    "successful" : 3,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 11,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "twitter",
        "_type" : "_doc",
        "_id" : "VQWixnYBP-7LnBQtR_Rd",
        "_score" : 1.0,
        "_routing" : "kimchy",
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T14:12:12",
          "message" : "trying out Elasticsearch"
        }
      }
    ]
  }
}
```

返回结果包含一个 scroll_id，可以被传递给 scroll API 来检索下一个批次的结果。

- **二次搜索：** 每次对 scroll API 的调用返回了结果的下一个批次结果，直到 hits 数组为空。scroll_id 则可以在请求体中传递。scroll 参数告诉 Elasticsearch 保持搜索的上下文等待另一个3m。返回数据的size与初次请求一致。

```shell
POST /_search/scroll
{
  "scroll":"3m",
  "scroll_id": "DnF1ZXJ5VGhlbkZldGNoAwAAAAAAF2taFjZudThqQXAyVGVxWk04MUM3eEZDVEEAAAAAABdrWxY2bnU4akFwMlRlcVpNODFDN3hGQ1RBAAAAAAAXa1kWNm51OGpBcDJUZXFaTTgxQzd4RkNUQQ=="
}

# 返回结果
{
  "_scroll_id" : "DnF1ZXJ5VGhlbkZldGNoAwAAAAAAF2zfFjZudThqQXAyVGVxWk04MUM3eEZDVEEAAAAAABds4BY2bnU4akFwMlRlcVpNODFDN3hGQ1RBAAAAAAAXbOEWNm51OGpBcDJUZXFaTTgxQzd4RkNUQQ==",
  "took" : 1,
  "timed_out" : false,
  "terminated_early" : true,
  "_shards" : {
    "total" : 3,
    "successful" : 3,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 11,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [ ]
  }
}
```

**NOTE:** 原理上来说可以把 scroll 分为初始化和遍历两步，初始化时将所有符合搜索条件的搜索结果缓存起来，可以想象成快照，在遍历时，从这个快照里取数据，也就是说，在初始化后对索引插入、删除、更新数据都不会影响遍历结果。因此，scroll 并不适合用来做实时搜索，而更适用于后台 **批处理任务，比如群发**。

- **三次操作**: 删除 scroll_id

```shell
DELETE /_search/scroll
{
    "scroll_id" : "DnF1ZXJ5VGhlbkZldGNoAwAAAAAAF2zfFjZudThqQXAyVGVxWk04MUM3eEZDVEEAAAAAABds4BY2bnU4akFwMlRlcVpNODFDN3hGQ1RBAAAAAAAXbOEWNm51OGpBcDJUZXFaTTgxQzd4RkNUQQ=="
}
```



##　scroll  的高效滚动

scroll API 保持了那些已经返回记录结果，所以能更加高效地返回排序的结果。但是，按照默认设定排序结果仍然需要代价。

一般来说，你仅仅想要找到结果，不关心顺序如果目的是为了遍历所有结果，而不关心结果的顺序，那么可以按 `"sort": [ "_doc"] `排序来提高性能

```shell
# 第一步
POST /twitter/_search?scroll=3m
{
  "query": {
    "match": {
      "user": "kimchy"
    }
  },
  "size": 10, 
 "sort": ["_doc"]
}
# 第二步
POST /_search/scroll
{
  "scroll":"1m",
  "scroll_id":"DnF1ZXJ5VGhlbkZldGNoAwAAAAAAF3NLFjZudThqQXAyVGVxWk04MUM3eEZDVEEAAAAAABdzTRY2bnU4akFwMlRlcVpNODFDN3hGQ1RBAAAAAAAXc0wWNm51OGpBcDJUZXFaTTgxQzd4RkNUQQ=="
}
```

scroll和`scroll + "sort": ["_doc"]`有一些差别，如下所示：

1. `scroll + "sort": ["_doc"]`不进行文本相似度计算，不排序，按照索引中的数据顺序返回
2. `scroll + "sort": ["_doc"]`不支持聚合操作。
3. 初始 search 请求的响应不会在 hits 数组中包含任何结果。第一批结果就会按照第一个 scroll 请求返回。
4. `scroll + "sort": ["_doc"]`的参数size代表着每个分片上的请求的结果数量，每次返回n*size条数据。而scroll每次返回size条数据

### NOTE:

**与 from/size 分页方式不同，使用 scroll 分页只能单向顺序翻页，不能随机翻页，适用于遍历结果集的场景。**

**scroll 翻页能够深度翻页，但是翻页期间需要维护“search context”，这是需要占用一定资源的。**

**对于用户高并发访问的场景，不推荐用这种方式，scroll 更适用于批处理类的后台任务.**

# Search after 分页

scroll 的方式，官方的建议不用于实时的请求（一般用于数据导出），因为每一个scroll_id 不仅会占用大量的资源，而且会生成历史快照，对于数据的变更不会反映到快照上。

search_after 分页的方式是根据上一页的最后一条数据来确定下一页的位置，同时在分页请求的过程中，如果有索引数据的增删改查，这些变更也会实时的反映到游标上。但是需要注意，因为每一页的数据依赖于上一页最后一条数据，所以无法跳页请求。

为了找到每一页最后一条数据，每个文档必须有一个全局唯一值，官方推荐使用 _uid 作为全局唯一值，其实使用业务层的 id 也可以。

## 首次查询

```shell
POST /twitter/_search
{
    "size":2,
    "query": {
        "match" : {
            "user" : "kimchy"
        }
    },
    "sort": [
        {"_id": "asc"}
    ]
}
# 返回结果
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 3,
    "successful" : 3,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 3,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [
      {
        "_index" : "twitter",
        "_type" : "_doc",
        "_id" : "VQWixnYBP-7LnBQtR_Rd",
        "_score" : null,
        "_routing" : "kimchy",
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T14:12:12",
          "message" : "trying out Elasticsearch"
        },
        "sort" : [
          1258294332000
        ]
      },
      {
        "_index" : "twitter",
        "_type" : "_doc",
        "_id" : "1",
        "_score" : null,
        "_source" : {
          "user" : "kimchy",
          "post_date" : "2009-11-15T14:12:12",
          "message" : "trying out Elasticsearch"
        },
        "sort" : [
          1258294332000
        ]
      }
    ]
  }
}
```

## 第二次查询

```shell
# 第二次搜索: search_after 为上次查询结果中最后一条记录的 sort 值
POST /twitter/_search
{
    "size":1,
    "query": {
        "match" : {
            "user" : "kimchy"
        }
    },
    "sort": [
        {"_id": "desc"}
    ],
    "search_after":["VAWaxnYBP-7LnBQtz_TX"]
}
```

**note:**

出现警告: `Deprecation: Loading the fielddata on the _id field is deprecated and will be removed in future versions. If you require sorting or aggregating on this field you should also include the id in the body of your documents, and map this field as a keyword field that has [doc_values] enabled`. 不希望我们使用 _id 来排序,建议自定义业务字段.

按照第一个检索到的最后显示的“updateTime”，search_after及多个排序字段多个参数用逗号隔开，作为下一个检索search_after的参数。
当使用search_after参数时，from的值必须被设为0或者-1.



# 总结

- 如果数据量小（10000条内），或者只关注结果集的TopN数据，可以使用from / size 分页，简单粗暴
- 数据量大，深度翻页，后台批处理任务（数据迁移）之类的任务，使用 scroll 方式
- 数据量大，深度翻页，用户实时、高并发查询需求，使用 search after 方式



